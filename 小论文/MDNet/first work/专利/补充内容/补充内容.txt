########################################################################################################################################
1.特征分割——跳跃连接
由于网络层次的深浅和过滤器大小的不同，CNN可以捕捉低级、高级的特征。
其中网络浅层提取的特征与输入比较近，包含更多的像素点的信息。由于网络层数较少所以其特征感受野较小，感受野重叠区域较小，提取到的是图像的细粒度信息，例如图像的一些颜色、纹理、边缘等。这被称为局部信息
因此浅层特征分辨率更高，包含更多位置、细节信息，但是由于经过的卷积更少，其语义性更低，噪声更多。

网络深层提取的特征离输出较近，包含更多的是更抽象的信息，即语义信息。此外随着网络层数增加图像信息进行压缩、特征感受野不断增大，感受野之间重叠区域增加，提取到的是图像的粗粒度信息，例如图像整体性的一些信息。这被称为全局信息
具有更强的语义信息，但是分辨率很低，对细节的感知能力较差。

分割是一种精细的分类，需要对图像中的每个像素进行分类。
一方面医学分割目标在人体图像中的分布很具有规律，语义简单明确，低分辨率信息能够提供这一信息，用于目标物体的识别。
另一方面息肉图像有其特殊性目标（息肉）与其背景（肠道）颜色十分相似、边缘轮廓相比自然图像较为模糊、梯度复杂，故对于息肉分割而言，在分割需要较多的高分辨率信息。
UNet的编码解码结构恰好能结合低分辨率信息（提供物体类别识别依据）和高分辨率信息（提供精准分割定位依据），完美适用于医学图像分割。

因此，在特征分割部分我们借鉴Unet的设计结构，通过跳跃连接将高低分辨率特征结合；同时设计与编码部分对称的解码结构逐步恢复目标的细节和相应的空间维度。
*****************用图说明  1.浅层关注边缘 2.深层关注全局  √3.浅层感受野小 √4.深层感受野大*****************************************
########################################################################################################################################
2.特征分类——由resnet101换成vgg19并且不带bn
在本公开数据集的论文中，作者Krushi PatelI等人对经典的分类模型：VGG、ResNet、DenseNet、SENet、MnasNet进行了对比实验
实验结果表明VGG19在本数据集上的总体准确率达到79.78%，优于其他所有模型，这表明在VGG之后提出的模型，如ResNet、SENet和MnasNet，虽然在通用图像分类数据集上比VGG-19有更好的性能，但在本结肠息肉数据集上都表现不佳。
此外，在结果中还观察到VGG-19在大多数指标上都优于带批归一化的VGG-19，其原因可能是在息肉分类中，像素的精确强度值可能比一般图像分类更有助于区分不同类型的息肉。而批归一化层相对于批缩放像素值，这可能会影响强度信息并降低性能。
考虑到以上原因，我们将原论文特征分类模块的网络结构换成了不带批归一化的VGG19。这有利于获得更高的精度、使网络更适合结肠息肉图像。
************************用表格说明   1.不同模型分类结果  ******************************
########################################################################################################################################
3.目标检测——用WSDDN替换OICR
WSDDN缺点
（1）丢失实例: 一幅图像中如果有多个同类实例时，往往只会检测到显著的一个或几个实例，而丢失其他实例；
（2）容易把邻近的同一类的多个实例检测成同一个实例；
（3）检测框容易只框选出实例目标的显著部分，框不全。
（4）依赖于区域推荐算法的限制，没有收到推荐的区域将不会被检测到。
OICR（局部聚焦问题）
为了缓解区分区域问题，OICR使用WSDDN作为其基线，并在基线后添加了三个实例分类器细化过程。
每个实例分类器细化过程由两个完全连接的层组成，旨在进一步预测每个建议的类别分数。
因为每个实例分类器细化过程的输出是对其后一个细化过程的监督，所以OICR可以继续学习，以便更大的区域可以具有比WSDDN更高的分数。
虽然WSDDN的预测可能只关注目标的区分部分，但它将在几个实例分类器细化过程后得到细化。


****************************************************************************************************************************************************************************************************
弱监督目标检测开山之作是WSDDN，但由于WSDDN存在丢失实例（1）、容易把邻近的同一类的多个实例检测成同一个实例（2）、检测框容易只框选出实例目标的显著部分，框不全的不足（3）的问题，OICR被提出以改进WSDDN。
OICR使用WSDDN作为其基线，并在基线后添加了三个实例分类器细化过程，每个实例分类器细化过程由两个完全连接的层组成，旨在进一步预测每个建议的类别分数。
每个实例分类器细化过程的输出是对其后一个细化过程的监督，使更大的区域可以具有比WSDDN更高的分数。
在SDCN论文中，作者采用OICR技术对目标进行检测。然而我们认为这是不合适的：
首先，就结肠息肉图像而言，虽然临床中存在一张图像中存在大量不同类别息肉的情况，但据目前我们所知的公开的数据集中还并未涉及。已有公开结肠息肉数据集每张图像中仅有一类息肉且不存在一类多实例的情况，因此我们的工作不受WSDDN这一缺点的影响。
其次，对于框选出实例目标的显著部分，框不全的问题我们的协作机制将会改善；
再者，对比WSDDN，OICR虽精度有所提升但其网络结构复杂，此外对比OICR与WSDDN的实验结果可知，OICR精度的提升在于某些符合这一训练策略类的提升，并不是每个类别的精度都提升，有些类别精度反而下降，而结肠息肉图像并不一定符合这种训练策略，因此在OICR性能提升策略对于结肠息肉图像并不适用。
最后，OICR需要用到三个实例分类器进行细化，与WSDDN相比训练更耗时。并且每个实例分类器细化过程的输出是对其后一个细化过程的监督。所以网络在训练中不仅需要保存当前实例分类器的结果、同时还需要保存上一个实例分类器的结果，这会造成更大数据量存储，需要更强大的硬件支持。
所以，我们改进了SDCN的目标检测网络框架以适应结肠息肉图像的检测，同时降低网络架构对硬件的要求，减少训练时间。


